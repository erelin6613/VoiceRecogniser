{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"#!pip install ../input/transformers/transformers-master/\n#!pip install keras_preprocessing\n#!pip install PyAudio","execution_count":34,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# My endeavor is to build a voice recognition model\n# that takes into account a language peculiarities.\n\n# For now model is not complete and even though the\n# notebook runs with no errors, it does not work as\n# intended. But I am developing it gradually.\n\n# Thanks Kaggle for the Notebook to persue our\n# crazy ideas :)\n\nimport pandas as pd\nfrom scipy.io import wavfile\nimport os\nimport librosa\nimport matplotlib.pyplot as plt\nimport numpy as np\n#from sklearn.metrics.pairwise import cosine_similarity\nfrom keras_preprocessing.sequence import pad_sequences\nfrom keras.models import Model\nfrom keras.layers import Dense, LSTM, Dropout\n#import wave\n#from pydub import AudioSegment\n\"\"\"\nfrom transformers import BertModel, BertConfig, BertTokenizer\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch import Tensor, tanh, flatten, squeeze, mean, stft\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.optim import Adam\nfrom torch.nn.utils.rnn import pad_sequence\n\"\"\"\nfrom torchaudio import load\nfrom torchaudio.transforms import MFCC, Resample\nfrom torchaudio.functional import istft\nimport numpy as np","execution_count":35,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_dir = '../input/common-voice'\naudio_dir = 'cv-valid-train'\n#/cv-valid-train'\nsound_len = 10\nbert_path = '../input/bert-base-uncased'\nbert_vocab_path = 'vocab.txt'\nbert_model_path = 'bert-base-uncased/pytorch_model.bin'\nmax_len_text = 30\nwindow = 40\n#n_mfcc=40","execution_count":40,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class VoiceInstance:\n    \n    def __init__(self, file, tokenizer=None, sound_len=10**10, text=None):\n        \n        self.file = file\n        self.text = text\n        self.tokenizer = tokenizer\n        #self.mp3 = mp3\n        self._transform_audio()\n        self.emb = self._get_embeddings()\n        \n    @staticmethod\n    def pad_seq(sequence):\n        return Tensor(np.pad(sequence, 0))\n    \n    def _transform_audio(self):\n        \n        waveform, rate = load(os.path.join(data_dir, self.file))\n        new_rate = rate/100\n        resampled = Resample(rate, new_rate)(waveform)\n        self.fft = np.real(self._get_fft(resampled, new_rate))\n        self.mfcc = self._get_mfcc(resampled, new_rate)\n        \n    def _get_mfcc(self, arr, sample_rate=22000):\n        \n        mfcc_tensor = MFCC(sample_rate, n_mfcc=window)\n        return mfcc_tensor.forward(arr)\n    \n    def _get_fft(self, waveform, rate):\n        return np.fft.fft(waveform, int(rate))\n    \n    def _get_embeddings(self):\n        #configuration = BertConfig()\n        \n        def remove_punkts(text):\n            \n            punkts = ['.', '?', '!', '\\'', '\"', '’', '‘', ',', ';']\n            for punkt in punkts:\n                text = str(self.text).replace(punkt, '')\n            return text\n        \n        def tokenize_text(text):\n            return self.tokenizer.tokenize(text)\n        \n        def get_inputs(tokens):\n            return self.tokenizer.convert_tokens_to_ids(tokens)\n        \n        if self.text:\n            self.text = remove_punkts(self.text)\n            self.tokens = tokenize_text(self.text)\n            emb = get_inputs(self.tokens)\n            return emb","execution_count":49,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(os.path.join(data_dir, 'cv-valid-train/cv-valid-train/sample-000005.mp3'))\nvoice = VoiceInstance('cv-valid-train/cv-valid-train/sample-000005.mp3')\nprint(voice.fft)\nprint(max(voice.fft))","execution_count":52,"outputs":[{"output_type":"stream","text":"../input/common-voice/cv-valid-train/cv-valid-train/sample-000005.mp3\n[[-8.11446667e-04  4.42126984e-05  2.05489988e-03  2.09994725e-03\n  -1.12488154e-03 -3.44713802e-03 -3.30752017e-03  1.15961014e-04\n   3.11731104e-03  2.70661404e-03 -4.24818265e-04 -3.60298243e-03\n  -3.98823046e-03 -6.27208423e-04  3.08787542e-03  4.38274048e-03\n   2.74208398e-03  2.41267409e-04 -2.20104598e-03 -2.77609015e-03\n  -1.93124986e-03  4.27663179e-04  2.25960075e-03  2.70231785e-03\n   6.94152351e-04 -2.45813675e-03 -4.91438640e-03 -3.94579171e-03\n  -9.22466171e-04  2.74758013e-03  4.10025755e-03  3.10189590e-03\n   4.15790900e-04 -1.28997344e-03 -1.92993746e-03 -6.51422317e-04\n  -3.17707697e-04 -3.43604017e-04  3.15391475e-04  3.54251925e-04\n   4.49142899e-04  1.17902578e-04 -3.92199525e-04  5.78316573e-04\n   1.70865088e-03  8.39619554e-04 -1.45527965e-03 -3.44420024e-03\n  -3.39578830e-03 -2.30221607e-03  1.48322940e-03  4.34094872e-03\n   2.75859053e-03 -2.85721253e-04 -2.77152842e-03 -2.75916647e-03\n  -5.71754453e-04  1.47385430e-03  1.49962178e-03  1.05602036e-03\n   4.13692359e-05  8.93488530e-04  4.18449065e-04 -6.65200329e-04\n  -3.05952856e-03 -3.51514295e-03 -2.43430611e-03  8.30346290e-04\n   3.40521697e-03  3.57744011e-03  1.62982821e-03 -5.64727626e-04\n  -1.49491073e-03 -1.69127798e-03 -2.18188956e-03 -2.84888235e-03\n  -1.85203535e-03  2.19785931e-03  5.07238456e-03  4.90435577e-03\n   3.92384003e-04 -4.17287809e-03 -5.63884543e-03 -2.54097952e-03\n   1.89251365e-03  3.51413314e-03  5.23922709e-04 -3.16209365e-03\n  -3.07161066e-03 -2.00661628e-04  2.72740555e-03  1.86820323e-03\n  -1.46411956e-03 -4.04465067e-03 -1.93269589e-03  2.35320268e-03\n   4.73316146e-03  3.82405176e-03  2.73210460e-04 -2.01948749e-03\n  -1.98799875e-03 -1.32097495e-04  6.24568467e-04  7.43181362e-04\n   1.52806445e-03  3.70007844e-04 -1.12616595e-04 -2.13290434e-03\n  -3.16014521e-03 -3.64336735e-03  7.01166492e-04  4.53199108e-03\n   4.19999269e-03  3.64120625e-04 -4.03038275e-03 -6.82929353e-03\n  -7.18197477e-04  3.45082179e-03  7.29463140e-03  4.61623453e-03\n   5.84430097e-03 -1.27376875e-03 -3.53388426e-03 -3.75237623e-03\n  -6.67824002e-04 -3.63948746e-04  1.29078081e-03  2.02557136e-03\n  -1.93210949e-04 -7.90599322e-03 -9.79969861e-03 -7.98030813e-03\n   7.94714524e-04  1.35712903e-02  1.80852602e-02  1.06852341e-02\n  -6.87349455e-03 -1.80089325e-02 -1.91443883e-02 -8.90506377e-03\n   2.41293214e-03  1.66584687e-02  1.74651084e-02  1.23753027e-02\n   3.72210674e-03 -8.64209736e-03 -1.95881079e-02 -2.34144024e-02\n  -1.50148137e-02  5.54506079e-03  2.90931335e-02  3.78122783e-02\n   2.32512171e-02 -8.76174888e-03 -3.99687415e-02 -4.04795015e-02\n  -2.04749835e-02  7.95152052e-03  3.68677464e-02  3.50305668e-02\n   2.95063890e-02  1.10334005e-02 -1.89070889e-02 -4.60195460e-02\n  -5.57504522e-02 -3.82309621e-02  1.42934478e-02  6.51946117e-02\n   8.12538375e-02  4.11729565e-02 -2.80227561e-02 -8.72750637e-02\n  -9.70609855e-02 -5.51065390e-02  2.03947799e-02  8.69622554e-02\n   1.25127038e-01  1.07544427e-01  2.34160740e-02 -9.08505316e-02\n  -1.80447182e-01 -1.50591551e-01  2.04177858e-03  1.80780026e-01\n   2.46229102e-01  1.06635585e-01 -1.42730119e-01 -3.16472373e-01\n  -2.47655262e-01  2.58169685e-02  2.86666267e-01  3.31463456e-01\n   1.16721234e-01 -1.63597760e-01 -2.80855627e-01 -1.58113014e-01\n   7.69807795e-02  2.17030615e-01  1.54081623e-01 -2.58551420e-02\n  -1.55556999e-01 -1.36285172e-01 -1.83727073e-02  7.72371813e-02\n   8.33345636e-02  2.23638810e-02 -2.67558150e-02 -2.31822312e-02\n   1.36364538e-03  3.61180899e-03 -1.48953978e-02 -3.62334176e-02\n  -1.34102793e-02  2.06108808e-02  4.16610138e-02  2.27020317e-02\n  -1.53598832e-02 -3.01670293e-02 -1.75756987e-02  1.10350432e-02\n   2.19604021e-02  1.05763615e-02 -8.10786199e-03 -1.42971231e-02\n  -3.91859598e-03  6.19706260e-03  7.55765932e-03 -4.45491191e-04\n  -5.27697330e-03 -1.30855946e-03  4.67030340e-03  4.07611035e-03\n  -9.02582498e-05 -3.59492447e-03 -3.51094125e-03  2.63683854e-04\n   2.74892279e-03  4.58878960e-03  1.29623651e-03 -6.89323586e-04\n   8.29551834e-04 -6.89323586e-04  1.29623651e-03  4.58878960e-03\n   2.74892279e-03  2.63683854e-04 -3.51094125e-03 -3.59492447e-03\n  -9.02582498e-05  4.07611035e-03  4.67030340e-03 -1.30855946e-03\n  -5.27697330e-03 -4.45491191e-04  7.55765932e-03  6.19706260e-03\n  -3.91859598e-03 -1.42971231e-02 -8.10786199e-03  1.05763615e-02\n   2.19604021e-02  1.10350432e-02 -1.75756987e-02 -3.01670293e-02\n  -1.53598832e-02  2.27020317e-02  4.16610138e-02  2.06108808e-02\n  -1.34102793e-02 -3.62334176e-02 -1.48953978e-02  3.61180899e-03\n   1.36364538e-03 -2.31822312e-02 -2.67558150e-02  2.23638810e-02\n   8.33345636e-02  7.72371813e-02 -1.83727073e-02 -1.36285172e-01\n  -1.55556999e-01 -2.58551420e-02  1.54081623e-01  2.17030615e-01\n   7.69807795e-02 -1.58113014e-01 -2.80855627e-01 -1.63597760e-01\n   1.16721234e-01  3.31463456e-01  2.86666267e-01  2.58169685e-02\n  -2.47655262e-01 -3.16472373e-01 -1.42730119e-01  1.06635585e-01\n   2.46229102e-01  1.80780026e-01  2.04177858e-03 -1.50591551e-01\n  -1.80447182e-01 -9.08505316e-02  2.34160740e-02  1.07544427e-01\n   1.25127038e-01  8.69622554e-02  2.03947799e-02 -5.51065390e-02\n  -9.70609855e-02 -8.72750637e-02 -2.80227561e-02  4.11729565e-02\n   8.12538375e-02  6.51946117e-02  1.42934478e-02 -3.82309621e-02\n  -5.57504522e-02 -4.60195460e-02 -1.89070889e-02  1.10334005e-02\n   2.95063890e-02  3.50305668e-02  3.68677464e-02  7.95152052e-03\n  -2.04749835e-02 -4.04795015e-02 -3.99687415e-02 -8.76174888e-03\n   2.32512171e-02  3.78122783e-02  2.90931335e-02  5.54506079e-03\n  -1.50148137e-02 -2.34144024e-02 -1.95881079e-02 -8.64209736e-03\n   3.72210674e-03  1.23753027e-02  1.74651084e-02  1.66584687e-02\n   2.41293214e-03 -8.90506377e-03 -1.91443883e-02 -1.80089325e-02\n  -6.87349455e-03  1.06852341e-02  1.80852602e-02  1.35712903e-02\n   7.94714524e-04 -7.98030813e-03 -9.79969861e-03 -7.90599322e-03\n  -1.93210949e-04  2.02557136e-03  1.29078081e-03 -3.63948746e-04\n  -6.67824002e-04 -3.75237623e-03 -3.53388426e-03 -1.27376875e-03\n   5.84430097e-03  4.61623453e-03  7.29463140e-03  3.45082179e-03\n  -7.18197477e-04 -6.82929353e-03 -4.03038275e-03  3.64120625e-04\n   4.19999269e-03  4.53199108e-03  7.01166492e-04 -3.64336735e-03\n  -3.16014521e-03 -2.13290434e-03 -1.12616595e-04  3.70007844e-04\n   1.52806445e-03  7.43181362e-04  6.24568467e-04 -1.32097495e-04\n  -1.98799875e-03 -2.01948749e-03  2.73210460e-04  3.82405176e-03\n   4.73316146e-03  2.35320268e-03 -1.93269589e-03 -4.04465067e-03\n  -1.46411956e-03  1.86820323e-03  2.72740555e-03 -2.00661628e-04\n  -3.07161066e-03 -3.16209365e-03  5.23922709e-04  3.51413314e-03\n   1.89251365e-03 -2.54097952e-03 -5.63884543e-03 -4.17287809e-03\n   3.92384003e-04  4.90435577e-03  5.07238456e-03  2.19785931e-03\n  -1.85203535e-03 -2.84888235e-03 -2.18188956e-03 -1.69127798e-03\n  -1.49491073e-03 -5.64727626e-04  1.62982821e-03  3.57744011e-03\n   3.40521697e-03  8.30346290e-04 -2.43430611e-03 -3.51514295e-03\n  -3.05952856e-03 -6.65200329e-04  4.18449065e-04  8.93488530e-04\n   4.13692359e-05  1.05602036e-03  1.49962178e-03  1.47385430e-03\n  -5.71754453e-04 -2.75916647e-03 -2.77152842e-03 -2.85721253e-04\n   2.75859053e-03  4.34094872e-03  1.48322940e-03 -2.30221607e-03\n  -3.39578830e-03 -3.44420024e-03 -1.45527965e-03  8.39619554e-04\n   1.70865088e-03  5.78316573e-04 -3.92199525e-04  1.17902578e-04\n   4.49142899e-04  3.54251925e-04  3.15391475e-04 -3.43604017e-04\n  -3.17707697e-04 -6.51422317e-04 -1.92993746e-03 -1.28997344e-03\n   4.15790900e-04  3.10189590e-03  4.10025755e-03  2.74758013e-03\n  -9.22466171e-04 -3.94579171e-03 -4.91438640e-03 -2.45813675e-03\n   6.94152351e-04  2.70231785e-03  2.25960075e-03  4.27663179e-04\n  -1.93124986e-03 -2.77609015e-03 -2.20104598e-03  2.41267409e-04\n   2.74208398e-03  4.38274048e-03  3.08787542e-03 -6.27208423e-04\n  -3.98823046e-03 -3.60298243e-03 -4.24818265e-04  2.70661404e-03\n   3.11731104e-03  1.15961014e-04 -3.30752017e-03 -3.44713802e-03\n  -1.12488154e-03  2.09994725e-03  2.05489988e-03  4.42126984e-05]]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"class VoiceDataset(Dataset):\n    \n    def __init__(self, info_frame, audio_dir, tokenizer):\n        \n        self.info_frame = info_frame\n        self.audio_dir = audio_dir\n        self.tokenizer = tokenizer\n        self.load_data()\n    \n    def __len__(self):\n        #gen = (x for x in self.instances)\n        return len(self.instances)\n    \n    def __getitem__(self, item):\n        return item\n    \n    def load_data(self):\n        \n        self.instances = []\n        for i in self.info_frame.index:\n            if self.info_frame.loc[i, 'text'] is not None:\n                audio = VoiceInstance(file=os.path.join(self.audio_dir, self.info_frame.loc[i, 'filename']),\n                                      text=self.info_frame.loc[i, 'text'], tokenizer=self.tokenizer)\n                self.instances.append(audio)\n        embs = []\n        mfccs = []\n        for each in self.instances:\n            embs.append(each.emb)\n            mfccs.append(each.mfcc)\n        embs = pad_sequences(embs, maxlen=max_len_text, padding='pre', value=0)\n        #mfccs = pad_sequences(mfccs, maxlen=max_len_text, padding='pre', value=0)\n        for i in range(len(self.instances)):\n            self.instances[i].emb = embs[i]\n            #self.instances[i].mfcc = mfccs[i]\n            #print(self.instances[i].emb)\n        # print('max length:', np.max(np.array(self.instances)))","execution_count":2,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'Dataset' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-6aef5fbdf70e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mVoiceDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maudio_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo_frame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minfo_frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'Dataset' is not defined"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"class VoiceModel(nn.Module):\n    \n    def __init__(self):\n        \n        super().__init__()\n        self.lstm_enc = nn.LSTM(input_size=window, hidden_size=512, batch_first=True)\n        self.lstm_dec = nn.LSTM(input_size=512, hidden_size=256)\n        #self.padding = nn.ConstantPad1d()\n        \n        \n        \n        self.input = nn.GRU(input_size=window, bidirectional=True, hidden_size=512)\n        self.gru = nn.GRU(input_size=512*2, bidirectional=False, hidden_size=512)\n        self.flatten = nn.Flatten()\n        #self.pool = nn.MaxPool1d(10)\n        self.dense = nn.Linear(256, 128)\n        self.dropout = nn.Dropout(0.3)\n        self.linear_2 = nn.Linear(128, max_len_text)\n        self.output = nn.Linear(max_len_text*100, 1)\n    \n    def forward(self, audio):\n        #print(audio.shape)\n        audio = Tensor(audio)\n        #print(audio)\n        #audio = nn.functional.pad(audio, (1, 0), mode='constant', value=0)\n        #print(audio.shape)\n        audio, hidden_enc = self.lstm_enc(audio.reshape(1, -1, window))\n        audio = tanh(audio)\n        audio, hidden_dec = self.lstm_dec(audio)\n        audio = tanh(audio)\n        audio = F.relu(self.dense(audio))\n        audio = self.flatten(audio)\n        # that's to see if it works, later I will figure an appropriate value\n        max_sound_len = 3000\n        audio = nn.functional.pad(audio, (max_sound_len-audio.shape[-1], 0), mode='constant', value=0)\n        audio = self.output(audio)\n        print(audio.shape)\n        \n        return audio","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"def main():\n    \n    #info_frame = pd.read_csv('../input/common-voice/cv-valid-train.csv')\n    \n    batch_size = 16\n    epochs = 10\n    model = VoiceModel()\n    criterion = nn.CosineSimilarity(dim=0)\n    #criterion.requres_grad = True\n    optimizer = Adam(model.parameters(), lr=0.001)\n    info_frame = pd.read_csv(os.path.join(data_dir, 'cv-valid-train.csv'))[:50]\t# .loc[25:75, :]\n    \n    tokenizer = BertTokenizer.from_pretrained(os.path.join(bert_path, bert_vocab_path), return_tensors='pt')\n    #model = BertModel.from_pretrained(os.path.join(bert_path, bert_model_path))\n    \n    real_texts = []\n    lengths = []\n    for i in info_frame.index:\n        tokens = tokenizer.tokenize(info_frame.loc[i, 'text'])\n        real_texts.append(tokenizer.convert_tokens_to_ids(tokens))\n        lengths.append(len(real_texts[i]))\n        \n    print(info_frame.columns)\n    #print(lengths)\n    \n    \n    dataset = VoiceDataset(info_frame=info_frame, audio_dir=audio_dir, tokenizer=tokenizer)\n    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n    #print(dataset.instances[0].fft)\n    \n    for epoch in range(epochs):\n        running_loss = 0\n        i=0\n        for batch in dataset.instances:\n            \n            optimizer.zero_grad()\n            #print(batch.fft) # torch.Size([1, 40, 10])\n            #print(batch.stft.shape)\n            output = model(batch.mfcc)\n            #print(output, batch.emb)\n            #loss = criterion(batch.emb, real_texts[i])\n            #print(batch.emb) #, real_texts[i])\n            #print('models output shape:', output.shape, '\\nlabels shape:', Tensor(batch.emb).shape)\n            #loss = criterion(output, Tensor(batch.emb))\n            \n            #loss.mean().backward()\n            #optimizer.step()\n            #running_loss += loss.item()\n            #print(running_loss)\n            i += 1\n        # print(loss.mean())\n        \n    model.eval()\n    \n    test_frame = pd.read_csv(os.path.join(data_dir, 'cv-valid-train.csv'))[50:75]\n    test_frame.reset_index()\n    print(test_frame.index)\n    \n    #real_embs = []\n    for text, file in zip(test_frame['text'], test_frame['filename']):\n        tokens = tokenizer.tokenize(text)\n        real_emb = tokenizer.convert_tokens_to_ids(tokens)\n        #lengths.append(len(real_texts[i]))\n        print('real embedding:', real_emb)\n        test_instance = VoiceInstance(file='cv-valid-train/'+file, \n                                      tokenizer=tokenizer)\n        pred = model(test_instance.mfcc)\n        print('predicted:', pred)\n            \nif __name__ == '__main__':\n    main()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}